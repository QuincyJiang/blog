title: 吴恩达深度学习课程笔记 第二周
date: 2018/11/15 11:52:50
categories: 机器学习
comments: true
tags: [机器学习,Tensorflow]
---

本博是吴恩达DeepLearning.ai 的学习笔记
从第二周开始记录

# 改善深层神经网络： 超参调试、正则化以及优化

## 训练集 开发集 测试集 的划分

假设所有的训练数据如下
![](/media/15422471488916.jpg)
一个典型的数据划分：
![](/media/15422472060092.jpg)

即：一部分作为 **训练集**
一部分作为 **简单交叉验证集/验证集**
一部分作为 **测试集**

具体的流程是 在**训练集**上 对**各模型运行训练算法** 将训练**完成的模型** 带入 **交叉验证集** 选择出最佳模型
然后带入**测试集**对神经网络做出**无偏评估**

小数据量的时候，一般会将数据划分为 **训练集（70%）** **测试集（30%）**或者**训练集（60%）、验证集（20%、测试集（20%）**。
在大数据量（百万级）时，验证集 测试集的数据量和小数据量的情况差不多，仍然可能需要成千上万，但是相比百万级的训练集来说，测试集所占的比例理所当然的变小了。比如我们拥有1000000，这么多的数据，**训练集：验证集：测试集=98:1:1**。
## 保证 验证集合测试集具有相同的分布
有时候 训练集和测试集的数据来源往往不同，比如说 训练集可能是通过爬虫爬取的网页图片，但是测试集是来自用户通过app上传的图片，这些图片的质量和对齐方式参差不齐，这种情况 最好能保证 **测试集和交叉验证集具有相同的分布。**
![](/media/15422532146088.jpg)

## 为什么要保证分布相同
我们先从测试集和验证集的作用开始说起
当我们在拿到数据后，会把数据划分为三部分，将训练集丢给模型，这个步骤是为了进行梯度下降，以期得到模型参数。
然后拿到训练完成的模型，带入验证集，这个部分是为了检查模型是否能够很好的拟合验证数据，因为这部分数据是没有经过梯度下降的，可以说验证集和测试集没有交
集，测试的准确率是可靠的。

但是模型除了**普通参数（w和b）**之外，还有**超参数**的存在，当不引入强化学习的情况下，普通参数可以被梯度下降更新，也就是可以被训练集更新，但是为了提高模型性能，我们往往会对 **神经网络层数、网络节点数、迭代次数、学习步长**等进行调整，这些参数不受梯度下降的影响，一般都是根据验证集的表现情况进行人为调整。

所以可以说，验证集也对学习结果产生了影响，所以需要一份完全没有经过学习影响的数据，来评估最终模型的表现情况，这个就是测试集存在的意义。

**为什么要保证测试集和验证集有相同的分布呢？**

因为一旦定义好了测试集和验证集，开发人员的目的就是专注提高验证集的表现，这便要求验证集的选取可以分布均匀，可以体现核心任务。如果验证集和测试集分布不同，就可能导致 **系统在验证集上表现良好，在测试集表现不好。**这种情况可能会有多种原因：

* 算法在开发集上过拟合了。
* 测试集比开发集更难进行预测，尽管算法做得足够好了，却很难有进一步的提升空间。
* 测试集不一定更难预测，但它与开发集性质并不相同（分布不同）。
因此在开发集上表现良好的算法不一定在测试集上也能够取得出色表现。
这样就引入了新的不确定性--**提高算法在验证集的表现，是否能提高其在测试集的表现？**如果是这种情况，大量针对开发集性能的改进工作将会是徒劳的。

## 如何评估模型表现？ 偏差、方差

**偏差(*bias*)：**可以理解为 模型在训练集的表现不佳 也就是模型无法很好的拟合数据  称之为欠拟合
**偏差(*variance*)：**模型在训练集表现良好，但在测试集表现差，模型过于拟合了训练集数据导致无法正确反映数据规律，称之为 过拟合

![](/media/15422574024898.jpg)

在实际中，判断偏差和方差一般会通过 训练集和测试集误差来判断

![](/media/15422578079564.jpg)

从左到右:
* **高方差**：模型过拟合了
* **高偏差**：模型没有被很好的训练 但是貌似没有过拟合 
* **高方差 高偏差：** 模型没有很好拟合数据 同时在测试集表现也不佳 有时有些高维数据中会出现这种情况，就是在某些区域的偏差高，有些区域的方差高
* **低方差 低偏差：** 模型可以很好表现数据特征

即：
**训练集误差高 表示 偏差大
测试集误差高 表示 方差大**

**关于方差和偏差的数学原理 ，见文章附录[1]。**


## 一个基本流程


```flow
st=>start: 获取数据
e=>end: 训练结束
op=>operation: 评估训练集误差（偏差值）
op1=>operation: 评估测试集误差（方差值）
op2=>operation: 选择更深层的神经网络或花费更多时间训练算法，或尝试更先进算法
op3=>operation: 获取更多数据，或者通过正则化减少过拟合
cond=>condition: 偏差正常?
cond2=>condition: 方差偏高?

st->op
op->cond
cond(yes)->op1
cond(no)->op2
op2->cond
op1->cond2
cond2(yes)->op3
cond2(no)->e
op3->cond2
```

在早期机器学习的时代，我们没有太多工具可以只影响偏差或者方差的一种而不对另一种造成影响，所以往往需要在两者间权衡。
现在在大数据时代，我们有了一些工具，比如只要对数据进行适当正则，再构建一个更大的神经网络，就可以在几乎不影响方差的情况下，减少偏差。而采用更多数据，或者对数据正则化，可以在不过多影响偏差的情况下，减少方差

## 降低方差的手段：正则化

出现高方差往往就表示，模型对数据过拟合了。
前面讲到 降低方差的手段，可以通过获取更多数据或者对数据进行正则来实现。

更多数据的获取，实现起来成本比较高，那正则化又为什么可以减少方差呢？




